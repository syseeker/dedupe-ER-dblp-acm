{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import unicodecsv as csv\n",
    "import pandas as pd\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout_dir         = \"output/DBLP_ACM/\"\n",
    "acm_csv          = \"ACM.csv\"\n",
    "dblp_csv         = \"DBLP2.csv\"\n",
    "futf_set1        = fout_dir + 'utf8_' + acm_csv\n",
    "futf_set2        = fout_dir + 'utf8_' + dblp_csv\n",
    "fnodes           = fout_dir + 'nodes.csv'\n",
    "fedges           = fout_dir + 'edges.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acm = pd.read_csv(futf_set1, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dblp2 = pd.read_csv(futf_set2, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkifstr(obj):\n",
    "    if isinstance(obj, float):\n",
    "        return False\n",
    "    else:\n",
    "        return bool(obj) and all(isinstance(elem, str) for elem in obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(column):\n",
    "    \"\"\"\n",
    "    Do a little bit of data cleaning with the help of Unidecode and Regex.\n",
    "    Things like casing, extra spaces, quotes and new lines can be ignored.\n",
    "    \"\"\"\n",
    "    column = unidecode(column)\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    column = re.sub('-', '', column)\n",
    "    column = re.sub('/', ' ', column)\n",
    "    column = re.sub(\"'\", '', column)\n",
    "    column = re.sub(\",\", '', column)\n",
    "    column = re.sub(\":\", ' ', column)\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    if not column :\n",
    "        column = None\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_dict(node_id, node_typ, node_label):\n",
    "    node_dict = {}\n",
    "    node_dict['Id'] = node_id\n",
    "    node_dict['Type'] = node_typ\n",
    "    node_dict['Label'] = node_label\n",
    "    return node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_dict(node1, rel, node2):\n",
    "    rel_dict = {}\n",
    "    rel_dict['Source'] = node1\n",
    "    rel_dict['Rel'] = rel\n",
    "    rel_dict['Target'] = node2\n",
    "    return rel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_coauthor_edge(authors_dict, authors_list):\n",
    "    co_authorship = []\n",
    "    for i in range(len(authors_list)):\n",
    "        for j in range(i+1, len(authors_list)):\n",
    "            node1 = authors_dict.get(authors_list[i])\n",
    "            node2 = authors_dict.get(authors_list[j])\n",
    "            rel = 'co-authored with'\n",
    "#             print (node1, \" co-authored with \", node2)\n",
    "            if node1 is not None and node2 is not None:\n",
    "                co_authorship.append(create_edge_dict(node1, rel, node2))\n",
    "            elif node1 is None:\n",
    "                print ('populate_coauthor_edge:', node1, ' not found')\n",
    "            elif node2 is None:\n",
    "                print ('populate_coauthor_edge:', node2, ' not found')\n",
    "    return co_authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_write_edge(authors_dict, authors_list, paper_dict, title_proc):\n",
    "    authoring = []\n",
    "    rel = 'wrote'\n",
    "    node2 = paper_dict.get(title_proc)\n",
    "    for i in range(len(authors_list)):\n",
    "        node1 = authors_dict.get(authors_list[i])\n",
    "        if node1:\n",
    "            authoring.append(create_edge_dict(node1, rel, node2))\n",
    "        else:\n",
    "            print ('populate_write_edge:', authors_list[i], ' not found')\n",
    "    return authoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(fname, headernames, data_arr, write_header):\n",
    "    with io.open(fname, 'a+b') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=headernames)\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        for r in data_arr:\n",
    "            writer.writerow(r)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of author nodes (name, paper-id, node-typ)\n",
    "df_acm_idx               = df_acm.set_index(['id'])\n",
    "df_acm_idstr             = df_acm['id'].astype(str).tolist()\n",
    "df_dblp2_idx             = df_dblp2.set_index(['id'])\n",
    "\n",
    "global_id                = 0\n",
    "NODE_TYP_AUTHOR_ACM      = 0\n",
    "NODE_TYP_AUTHOR_DBLP2    = 1\n",
    "NODE_TYP_PAPER_ACM       = 2\n",
    "NODE_TYP_PAPER_DBLP2     = 3\n",
    "\n",
    "dict_node                = {}     # map { id: original author or paper name}\n",
    "dict_node_acm_author     = {}     # map { author_proc_name: id}\n",
    "dict_node_dblp2_author   = {}\n",
    "dict_node_acm_paper      = {}     # map { paper_proc_name: id}\n",
    "dict_node_dblp2_paper    = {}     \n",
    "\n",
    "node_arr                 = []     # to create nodes.csv (including author and paper)\n",
    "author_paper_arr         = []     # to create 'author [writes] paper' rel. \n",
    "coauthor_link_arr        = []     # to create 'author [co-authored with] author' rel.\n",
    "\n",
    "for index, row in df_acm.iterrows():\n",
    "    acm_authors   = row['authors']\n",
    "    acm_title     = row['title']\n",
    "    \n",
    "    # Create paper node\n",
    "    proc_acm_title = preProcess(acm_title)\n",
    "    dict_node_acm_paper[proc_acm_title] = global_id\n",
    "    dict_node[global_id] = acm_title\n",
    "    node_prop = create_node_dict(global_id, NODE_TYP_PAPER_ACM, acm_title)\n",
    "    node_arr.append(node_prop)\n",
    "    global_id += 1\n",
    "    \n",
    "    # Populate co-author list\n",
    "    acm_authors_proc = []\n",
    "    \n",
    "    # Create author node\n",
    "    if checkifstr(acm_authors):\n",
    "        for oa in acm_authors.split(','):\n",
    "            a = preProcess(oa)\n",
    "            acm_authors_proc.append(a)\n",
    "            if a not in dict_node_acm_author:\n",
    "                dict_node_acm_author[a] = global_id\n",
    "                dict_node[global_id] = oa\n",
    "                node_prop = create_node_dict(global_id, NODE_TYP_AUTHOR_ACM, oa)\n",
    "                node_arr.append(node_prop)\n",
    "                global_id += 1\n",
    "                \n",
    "    # Populate co-author list\n",
    "    edges_list = populate_coauthor_edge(dict_node_acm_author, acm_authors_proc)\n",
    "    coauthor_link_arr.extend(edges_list)\n",
    "\n",
    "    # Populate authoring edge\n",
    "    edges_list = populate_write_edge(dict_node_acm_author, acm_authors_proc, dict_node_acm_paper, proc_acm_title)\n",
    "    author_paper_arr.extend(edges_list)\n",
    "    \n",
    "    \n",
    "write_csv(fnodes, ['Id', 'Type', 'Label'], node_arr, True)\n",
    "write_csv(fedges, ['Source', 'Rel', 'Target'], author_paper_arr, True)\n",
    "write_csv(fedges, ['Source', 'Rel', 'Target'], coauthor_link_arr, False)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def populate_graph(res_map, true_map):\n",
    "#     # Get a list of author nodes (name, paper-id, node-typ)\n",
    "#     df_acm_idx               = df_acm.set_index(['id'])\n",
    "#     df_acm_idstr             = df_acm['id'].astype(str).tolist()\n",
    "#     df_dblp2_idx             = df_dblp2.set_index(['id'])\n",
    "\n",
    "#     global_id                = 0\n",
    "#     NODE_TYP_AUTHOR_ACM      = 0\n",
    "#     NODE_TYP_AUTHOR_DBLP2    = 1\n",
    "#     NODE_TYP_PAPER_ACM       = 2\n",
    "#     NODE_TYP_PAPER_DBLP2     = 3\n",
    "\n",
    "#     dict_node                = {}     # map { id: original author or paper name}\n",
    "#     dict_node_acm_author     = {}     # map { author_proc_name: id}\n",
    "#     dict_node_dblp2_author   = {}\n",
    "#     dict_node_acm_paper      = {}     # map { paper_proc_name: id}\n",
    "#     dict_node_dblp2_paper    = {}     \n",
    "\n",
    "#     node_arr                 = []     # to create nodes.csv (including author and paper)\n",
    "#     author_paper_arr         = []     # to create 'author [writes] paper' rel. \n",
    "#     coauthor_link_arr        = []     # to create 'author [co-authored with] author' rel.\n",
    "\n",
    "#     for k, pred_v in res_map.items():\n",
    "#         if true_map.get(k) is not None:\n",
    "#             true_v = true_map.get(k)        \n",
    "#             if true_v == pred_v:\n",
    "#                 if k in df_acm_idstr:   # Filter only one-way\n",
    "#                     acm_authors   = df_acm_idx.loc[int(k)].authors\n",
    "#                     dblp2_authors = df_dblp2_idx.loc[pred_v].authors\n",
    "#                     acm_title     = df_acm_idx.loc[int(k)].title\n",
    "#                     dblp2_title   = df_dblp2_idx.loc[pred_v].title\n",
    "\n",
    "#                     # Create paper node\n",
    "#                     proc_acm_title = preProcess(acm_title)\n",
    "#                     dict_node_acm_paper[proc_acm_title] = global_id\n",
    "#                     dict_node[global_id] = acm_title\n",
    "#                     node_prop = create_node_dict(global_id, NODE_TYP_PAPER_ACM, acm_title, k)\n",
    "#                     node_arr.append(node_prop)\n",
    "#                     global_id += 1\n",
    "\n",
    "#                     proc_dblp2_title = preProcess(dblp2_title)\n",
    "#                     dict_node_dblp2_paper[proc_dblp2_title] = global_id\n",
    "#                     dict_node[global_id] = dblp2_title\n",
    "#                     node_prop = create_node_dict(global_id, NODE_TYP_PAPER_DBLP2, dblp2_title, pred_v)\n",
    "#                     node_arr.append(node_prop)\n",
    "#                     global_id += 1\n",
    "\n",
    "#                     # Populate co-author list\n",
    "#                     acm_authors_proc = []\n",
    "#                     dblp2_authors_proc = []\n",
    "\n",
    "#                     # Create author node\n",
    "#                     if checkifstr(acm_authors):\n",
    "#                         for oa in acm_authors.split(','):\n",
    "#                             a = preProcess(oa)\n",
    "#                             acm_authors_proc.append(a)\n",
    "#                             if a not in dict_node_acm_author:\n",
    "#                                 dict_node_acm_author[a] = global_id\n",
    "#                                 dict_node[global_id] = oa\n",
    "#                                 node_prop = create_node_dict(global_id, NODE_TYP_AUTHOR_ACM, oa, k)\n",
    "#                                 node_arr.append(node_prop)\n",
    "#                                 global_id += 1\n",
    "\n",
    "#                     if checkifstr(dblp2_authors):\n",
    "#                         for oa in dblp2_authors.split(','):\n",
    "#                             a = preProcess(oa)\n",
    "#                             dblp2_authors_proc.append(a)\n",
    "#                             if a not in dict_node_dblp2_author:\n",
    "#                                 dict_node_dblp2_author[a] = global_id\n",
    "#                                 dict_node[global_id] = oa\n",
    "#                                 node_prop = create_node_dict(global_id, NODE_TYP_AUTHOR_DBLP2, oa, pred_v)\n",
    "#                                 node_arr.append(node_prop)\n",
    "#                                 global_id += 1\n",
    "\n",
    "#                     # Populate co-author list\n",
    "#                     edges_list = populate_coauthor_edge(dict_node_acm_author, acm_authors_proc)\n",
    "#                     coauthor_link_arr.extend(edges_list)\n",
    "#                     edges_list = populate_coauthor_edge(dict_node_dblp2_author, dblp2_authors_proc)\n",
    "#                     coauthor_link_arr.extend(edges_list)\n",
    "                    \n",
    "#                     # Populate authoring edge\n",
    "#                     edges_list = populate_write_edge(dict_node_acm_author, acm_authors_proc, dict_node_acm_paper, proc_acm_title)\n",
    "#                     author_paper_arr.extend(edges_list)\n",
    "#                     edges_list = populate_write_edge(dict_node_dblp2_author, dblp2_authors_proc, dict_node_dblp2_paper, proc_dblp2_title)\n",
    "#                     author_paper_arr.extend(edges_list)\n",
    "                    \n",
    "#     return [node_arr, coauthor_link_arr, author_paper_arr]\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
